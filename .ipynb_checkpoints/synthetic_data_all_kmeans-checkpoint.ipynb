{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Master file with exp_name:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This script is actually merge all the files in clean_csv folder \n",
    "with additional columns to get the whole dataset. Now this version \n",
    "is more easier to work with as it has individual experiments. Each\n",
    "experients has individual names. So that pandas searching and slicing \n",
    "would be more easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import pandas library:\n",
    "import os\n",
    "import pandas as pd\n",
    "import pylab as pyl\n",
    "import numpy as np\n",
    "from scipy.interpolate import *\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pretty dataframe :\n",
    "from IPython.core.display import HTML\n",
    "css = open('style-table.css').read() + open('style-notebook.css').read()\n",
    "HTML('<style>{}</style>'.format(css))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Control variables: \n",
    "\n",
    "\n",
    "# master dataset location:\n",
    "master_location = 'Dropbox/gits/data/ThOpt/clean_csv/'\n",
    "\n",
    "# master file name : \n",
    "#file_name = 'ex4_EDData.csv'\n",
    "#file_name_med = 'ex2_enDataSG_2T.csv'\n",
    "#file_name_large = 'ex2_enDataSG_1T.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def change_type(df, col, dtype):\n",
    "    # This function change the column datatype\n",
    "    # df - main data frame - type: dataframe\n",
    "    # col - columns that you want to change data type - type: list\n",
    "    # dtype - new column type - type: list\n",
    "    # col and dtype must be equal in length\n",
    "\n",
    "    if len(col) != len(dtype):\n",
    "        print(\"col and dtype must be equal\")\n",
    "        return df\n",
    "    for col,n_type in zip(col,dtype):\n",
    "        df[col] = df[col].astype(n_type)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_unique_transfers(df, \n",
    "                          args = ['file_size','number_of_files','bandwidth','rtt','buffer_size']):\n",
    "    # find unique transfers:\n",
    "    # df - main dataframe\n",
    "    # args - list of columns you want for uniqueness\n",
    "\n",
    "    # get the unique transfers : as tuple \n",
    "    transfer_requests = df[args]\n",
    "    droped_duplicate_trans_req = transfer_requests.drop_duplicates()\n",
    "\n",
    "    unique_transfers = [tuple(transfers) for transfers in droped_duplicate_trans_req.values]\n",
    "    return unique_transfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_runs_1D(df, bk_tr, runs,colors,sort_order):\n",
    "    # This function plots runs\n",
    "    # df - main dataframe, type: dataframe\n",
    "    # bk_tr - background traffic type\n",
    "    # runs - list of runs you want to plot, type: List\n",
    "    # colors - list of colors for the graphs\n",
    "    # length of colors must be equal to (bk_tr X runs)\n",
    "    # sort_order - order of params, type: list. (for example 'p-cc-pp','pp-cc-p')\n",
    "    # \n",
    "    \n",
    "    if len(colors) != (len(bk_tr) * len(runs)) :\n",
    "        print(\"length of colors must be equal to (bk_tr X runs)\")\n",
    "        return\n",
    "    \n",
    "    \n",
    "    plt.figure(figsize=(35,13))\n",
    "    \n",
    "    df = df.sort(sort_order)\n",
    "    x_label = 'Parameter order - ' + sort_order[0] +', '+ sort_order[1] + ', ' + sort_order[2]\n",
    "    plt.xlabel(x_label, fontsize=40)\n",
    "    plt.ylabel('Throughput (Gbps)', fontsize=40)\n",
    "    title = 'Throughput Trajectory(4) - Parameter order - '+ sort_order[0] +', '+ sort_order[1] + ', ' + sort_order[2]\n",
    "    plt.title(title, fontsize=50)\n",
    "\n",
    "    #df = df.sort(['cc','p','pp'])\n",
    "    color_count = 0\n",
    "    for bk in bk_tr:\n",
    "        bk_data = df[df.background == bk]\n",
    "        for run in runs:\n",
    "            run_data = bk_data[bk_data.run_id == run]\n",
    "            num_rows = run_data.shape[0]\n",
    "            #df_list.append(run_data)\n",
    "            run_data['ticks'] = run_data[sort_order[0]].astype(str) + '-' \\\n",
    "                                + run_data[sort_order[1]].astype(str) + '-' \\\n",
    "                                + run_data[sort_order[2]].astype(str)\n",
    "\n",
    "\n",
    "            x_value = np.arange(1,num_rows+1)\n",
    "            x_value\n",
    "            y_value = np.array(run_data.throughput)\n",
    "            y_value.shape\n",
    "            tick_value = np.array(run_data.ticks)\n",
    "\n",
    "            plt.xticks(x_value[0:(num_rows+1):32], tick_value[0:(num_rows+1):32])\n",
    "            plt.tick_params(axis='both', which='major', labelsize=30)\n",
    "\n",
    "            plt.plot(x_value, y_value,colors[color_count],)\n",
    "            color_count = color_count + 1\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and merge data files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!ls ~/Dropbox/gits/data/ThOpt/clean_csv/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# required values :\n",
    "\n",
    "# OS file seperator: \n",
    "file_seperator = os.sep\n",
    "\n",
    "\n",
    "# User OS home directory:\n",
    "user_home = os.environ['HOME']\n",
    "user_home = user_home+file_seperator\n",
    "#user_home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_files_path = user_home + master_location\n",
    "list_of_logs = os.listdir(log_files_path)\n",
    "list_of_logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file_list = []\n",
    "for file_path in list_of_logs:\n",
    "    print(file_path)\n",
    "    url = user_home + master_location + file_path\n",
    "    temp_data = pd.read_csv(url)\n",
    "    \n",
    "    file_list.append(temp_data)\n",
    "data = pd.concat(file_list, ignore_index=True) \n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# See all the experiments:\n",
    "data.exp_name.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data[\"destination\"] = data[\"destination\"].replace(['Gordon/oasis','Gordon'],'Gordon/Oasis')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "find_unique_transfers(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get exp_2 data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "exp_2 = data[data.exp_name == \"exp_2_background_traffic\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the small data and only transfer from gordon and stampede:\n",
    "temp_exp2 = change_type(exp_2, [\"file_size\"], [\"int\"])\n",
    "exp_2_small = temp_exp2[(temp_exp2.file_size < 10000000) & (temp_exp2.destination == 'Gordon/Oasis') ] \n",
    "\n",
    "bk_traffic = [0,1,2]\n",
    "runs = [2]\n",
    "colors = ['ro','ro','ro']\n",
    "sort_order = ['cc','p','pp']\n",
    "plot_runs_1D(exp_2_small,bk_traffic,runs,colors, sort_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get all data and perform CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "temp_data = data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "args = ['file_size', 'number_of_files', 'bandwidth', 'rtt', 'buffer_size','source', 'destination','run_id', 'background']\n",
    "unique_req = find_unique_transfers(temp_data, args)\n",
    "num_reqs = len(find_unique_transfers(temp_data, args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "temp_data = temp_data.set_index(args)\n",
    "temp_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Ndarray for CNN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make each request a matrix of ndarray \n",
    "# with all requests make 264 * 32 * 32 matrix\n",
    "m = 32\n",
    "n = 32\n",
    "x = num_reqs\n",
    "\n",
    "mat = np.zeros([x,m+1,n+1])\n",
    "temp_mat = np.zeros([m+1,n+1])\n",
    "mat_yy = np.zeros(x)\n",
    "req_count = 0\n",
    "for req in unique_req:\n",
    "    current_req = temp_data.loc[req]\n",
    "    current_req = current_req.reset_index()\n",
    "    for index, row in current_req.iterrows():\n",
    "        mat[req_count, row.p, row.cc] = row.throughput\n",
    "        temp_mat[row.p, row.cc] = row.throughput\n",
    "        run_id = row.run_id\n",
    "    mat_yy[req_count] = np.sum(temp_mat)\n",
    "    #mat_y[req_count] = run_id\n",
    "    req_count = req_count + 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat_yy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "high = np.percentile(mat_yy,80)\n",
    "mid_high = np.percentile(mat_yy,60)\n",
    "mid = np.percentile(mat_yy,50)\n",
    "low_high = np.percentile(mat_yy,40)\n",
    "low = np.percentile(mat_yy,20)\n",
    "#profile = [low,low_high,mid,mid_high,high]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_to_discrete_traffic(x,high,mid_high,mid,low_high,low):\n",
    "    y = x\n",
    "    count = 0\n",
    "    for item in x:\n",
    "        if item >= high:\n",
    "            y[count] = 5\n",
    "        elif (item < high) and item >=mid_high:\n",
    "            y[count] = 4\n",
    "        elif(item < mid_high) and (item >= mid):\n",
    "            y[count] = 3\n",
    "        elif(item < mid) and (item >= low_high):\n",
    "            y[count] = 2\n",
    "        elif(item < low_high) and (item >= low):\n",
    "            y[count] = 1\n",
    "        else:\n",
    "            y[count] = 0\n",
    "        count = count + 1\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mat_y = convert_to_discrete_traffic(mat_yy,high,mid_high,mid,low_high,low)\n",
    "mat_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core CNN code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import theano \n",
    "import warnings\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split data for training and testing: \n",
    "training_idx = np.random.randint(mat.shape[0], size=220)\n",
    "test_idx = np.random.randint(mat.shape[0], size=44)\n",
    "X_train, X_test = mat[training_idx,:], mat[test_idx,:]\n",
    "y_train = mat_y[training_idx]\n",
    "y_test = mat_y[test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0], 1, 33, 33)\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 33, 33)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_train = np_utils.to_categorical(y_train, 12)\n",
    "Y_test = np_utils.to_categorical(y_test, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 7. Define model architecture\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1,33,33), \n",
    "                        dim_ordering='th'))\n",
    "#model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(1,28,28)))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(Convolution2D(32, 3, 3, activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(12, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 8. Compile model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 9. Fit model on training data\n",
    "history = model.fit(X_train, Y_train, \n",
    "          batch_size=32, nb_epoch=30, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "#plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "#plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffled_data = data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "suffled_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del suffled_data[\"run_id\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del suffled_data[\"fast\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "suffled_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "suffled_data.to_csv(\"logs_mixed_traffic_3runs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning]",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
