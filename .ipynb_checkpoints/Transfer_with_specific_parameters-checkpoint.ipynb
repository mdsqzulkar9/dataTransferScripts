{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys, time\n",
    "import datetime\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## User Control variables :\n",
    "\n",
    "# valid source values : \n",
    "#        stampede\n",
    "#        gordon\n",
    "source = 'stampede'   \n",
    "source_partition = 'scratch'   # can be scratch or home \n",
    "# valid destination_key values:\n",
    "#        stampede\n",
    "#        gordon    \n",
    "destination = 'gordon'  # can be : stampede or gordon\n",
    "destination_partition = 'scratch' # can be scratch or home \n",
    "\n",
    "# Dataset folder name :\n",
    "dataset_folder_name = 'medium'\n",
    "\n",
    "# directory for log file: \n",
    "log_file_dir = 'TransferLogFiles'\n",
    "\n",
    "# Measure those values or gather information about it : \n",
    "link_bandwidth = 10   # Giga-bit per second\n",
    "round_trip_time = 39 # milisecond\n",
    "buffer_size = (link_bandwidth*1024*39*1000)/8   # byte\n",
    "\n",
    "\n",
    "# Defined variables:\n",
    "site_name_to_url_dict ={\n",
    "    'stampede':'gsiftp://gridftp.stampede.tacc.xsede.org:2811',\n",
    "    'gordon':'gsiftp://oasis-dm2.sdsc.xsede.org:2811',\n",
    "}\n",
    "\n",
    "name_to_directory_dict = {\n",
    "    'stampede-home':'/home1/03644/zulkar9/',\n",
    "    'stampede-scratch':'/scratch/03644/zulkar9/',\n",
    "    'gordon-home':'/home/mdsqzulk/',\n",
    "    'gordon-scratch':'/oasis/scratch/mdsqzulk/temp_project/'   \n",
    "}\n",
    "\n",
    "\n",
    "if(source == destination):\n",
    "    print('Check control variables. Source and destination have same keys!')\n",
    "    sys.exit();\n",
    "\n",
    "\n",
    "# setup source url : \n",
    "source_url = site_name_to_url_dict[source]\n",
    "destination_url = site_name_to_url_dict[destination]\n",
    "\n",
    "\n",
    "# setup source and destination directory: \n",
    "source_key = source+\"-\"+source_partition\n",
    "destination_key = destination+\"-\"+destination_partition\n",
    "\n",
    "if (source_key == 'stampede-scratch'):\n",
    "    source_directory = name_to_directory_dict[source_key]\n",
    "elif (source_key =='stampede-home'):\n",
    "    source_directory = name_to_directory_dict[source_key]\n",
    "elif (source_key == 'gordon-home'):\n",
    "    source_directory = name_to_directory_dict[source_key]\n",
    "elif (source_key == 'gordon-scratch'):\n",
    "    source_directory = name_to_directory_dict[source_key]\n",
    "\n",
    "if (destination_key == 'stampede-scratch'):\n",
    "    destination_directory = name_to_directory_dict[destination_key]\n",
    "elif (destination_key =='stampede-home'):\n",
    "    destination_directory = name_to_directory_dict[destination_key]\n",
    "elif (destination_key == 'gordon-home'):\n",
    "    destination_directory = name_to_directory_dict[destination_key]\n",
    "elif (destination_key == 'gordon-scratch'):\n",
    "    destination_directory = name_to_directory_dict[destination_key]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function:\n",
    "def end_to_end_transfer(current_source_dir, current_destination_dir, parallelism, concurrency, pipelining, fast):\n",
    "    # Directory size calculation :\n",
    "    temp_var1 = os.popen(\"du -shb \"+current_source_dir).read()\n",
    "    temp_var2= temp_var1.split()\n",
    "    size_of_current_source_dir = int(temp_var2[0])   # size in byte\n",
    "\n",
    "    # Number of files calculation:\n",
    "    temp_var3 = os.popen(\"ls \"+current_source_dir+\" | wc -l\").read()\n",
    "    temp_var4= (str(temp_var3).split())[0]\n",
    "    nmbr_of_files_current_source_dir = int(temp_var4)\n",
    "\n",
    "    # Average file size :\n",
    "    average_file_size = size_of_current_source_dir / nmbr_of_files_current_source_dir\n",
    "\n",
    "    transfer_start_time = time.time()  # in seconds\n",
    "    # Executing Globus-url-copy with given parameters : with fast command ON\n",
    "    if fast == 1:\n",
    "        globus_url_copy_command = 'globus-url-copy -st 9999 -fast -tcp-bs '+str(buffer_size)+' -p '+str(parallelism)+' -cc '  \\\n",
    "                             + str(concurrency) + ' -ppq ' + str(pipelining) + ' ' + source_url+ current_source_dir + ' ' \\\n",
    "                                           + destination_url + current_destination_dir\n",
    "        print (globus_url_copy_command)\n",
    "    else:\n",
    "        globus_url_copy_command = 'globus-url-copy -st 9999 -tcp-bs '+str(buffer_size)+' -p '+str(parallelism)+' -cc '  \\\n",
    "                             + str(concurrency) + ' -ppq ' + str(pipelining) + ' '+ source_url + current_source_dir + ' ' \\\n",
    "                                        + destination_url + current_destination_dir\n",
    "        print (globus_url_copy_command)\n",
    "    os.system(globus_url_copy_command)\n",
    "    transfer_finish_time = time.time()  # in seconds\n",
    "\n",
    "    # Achieved throughput : computation:\n",
    "    time_required = transfer_finish_time - transfer_start_time\n",
    "    throughput = (size_of_current_source_dir *8) / time_required      # in bit per seconds\n",
    "\n",
    "    #throughput in MByte per second:\n",
    "    throughput = throughput /(8*1024*1024)    # in MBps\n",
    "\n",
    "    # log entry generation :\n",
    "    # log entry format:\n",
    "    # <avg.file size> <#ofFiles> <bandwidth> <RTT> <Buffer Size> <-p> <-cc> <-pp> <fast> <throughput> <time required>\n",
    "    #                                                                                                   <now-date-time>\n",
    "    temp_date_time = datetime.datetime.now()\n",
    "    now_date_time_str = temp_date_time.strftime('%m:%d:%Y-%H:%M')\n",
    "\n",
    "    if fast == 1:\n",
    "        log_entry = str(average_file_size) + \"\\t\" + str(nmbr_of_files_current_source_dir)+ \"\\t\" + str(link_bandwidth)  \\\n",
    "                + \"\\t\" + str(round_trip_time) + \"\\t\" + str(buffer_size) + \"\\t\" + str(parallelism) + \"\\t\" +  \\\n",
    "                str(concurrency) + \"\\t\" + str(pipelining) + \"\\t\" + \"1\\t\" + str(throughput) + \"\\t\" + str(time_required) \\\n",
    "                + \"\\t\" + now_date_time_str\n",
    "    else:\n",
    "        log_entry = str(average_file_size) + \"\\t\" + str(nmbr_of_files_current_source_dir) + \"\\t\" + str(link_bandwidth) \\\n",
    "                + \"\\t\" + str(round_trip_time) + \"\\t\" + str(buffer_size) + \"\\t\" + str(parallelism) + \"\\t\" +  \\\n",
    "                str(concurrency) + \"\\t\" + str(pipelining) + \"\\t\" + \"0\\t\" + str(throughput) + \"\\t\" + str(time_required) \\\n",
    "                + \"\\t\" + now_date_time_str\n",
    "\n",
    "    print(log_entry)\n",
    "\n",
    "    # Writing entry to log file:\n",
    "    log_file.write(log_entry+\"\\n\")\n",
    "    log_file.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function: \n",
    "# This method is responsible for varying the parameters :\n",
    "# start means - starting point of parameters\n",
    "# increment means - multiplicative increment\n",
    "# finish means - upper limit of parameters\n",
    "def transfer_with_varied_parameters(current_source_dir, current_destination_dir):\n",
    "    steps = math.log(finish,increment)\n",
    "    # initializing the parameters :\n",
    "    \n",
    "    # To do:\n",
    "    # get rid of the for loops. read those values from a file. \n",
    "    \n",
    "    parallelism = start\n",
    "    for i in range(steps+1):\n",
    "        concurrency = start\n",
    "        for j in range(steps+1):\n",
    "            pipelining = start\n",
    "            for k in range(steps+1):\n",
    "                fast = 0\n",
    "                end_to_end_transfer(current_source_dir, current_destination_dir, parallelism, concurrency, pipelining, fast)\n",
    "                fast = 1\n",
    "                end_to_end_transfer(current_source_dir, current_destination_dir, parallelism, concurrency, pipelining, fast)\n",
    "\n",
    "                # increase pipelining\n",
    "                pipelining = pipelining * increment\n",
    "\n",
    "            # end of for with k increment variable\n",
    "\n",
    "            #increment concurrency\n",
    "            concurrency = concurrency * increment\n",
    "        # end of for with j increment variable\n",
    "\n",
    "        #increment parallelism\n",
    "        parallelism = parallelism * increment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function :\n",
    "# This method is responsible for sending different level one directories in the\n",
    "# destination.\n",
    "def multiple_dir_transfer_with_varied_param():\n",
    "    # Listing all the level one folders\n",
    "    dataset_path = source_directory + dataset_folder_name + \"/\"\n",
    "    destination_dataset_path = destination_directory + dataset_folder_name + \"/\"\n",
    "    \n",
    "    temp_var1 = os.listdir(dataset_path)\n",
    "    #temp_var1 = os.system(\"ls \" + dataset_path)\n",
    "    print(\"temp_var1\")\n",
    "    print(temp_var1)\n",
    "    type(temp_var1)\n",
    "    #list_of_folders = temp_var1.split()\n",
    "    #for folder in list_of_folders:\n",
    "    for folder in temp_var1:\n",
    "        current_source_dir = dataset_path + folder + \"/\"\n",
    "        current_destination_dir = destination_dataset_path + folder + \"/\"\n",
    "        transfer_with_varied_parameters(current_source_dir, current_destination_dir, start, increment, finish)\n",
    "    # end of:  for folder in list_of_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "###############################################################################\n",
    "#########     MAIN EXECUTION POINT #############################################\n",
    "###############################################################################\n",
    "################################################################################\n",
    "\n",
    "\n",
    "# Log file : where transfer information will be saved!\n",
    "# File name is based on source destination and date time of execution\n",
    "# so no file will be overridden\n",
    "current_date_time = datetime.datetime.now()\n",
    "current_date_time_str = current_date_time.strftime('%m_%d_%Y_%H_%M')\n",
    "log_file_name = 'log_'+source_key+'_'+destination_key+'_'+'date'+current_date_time_str+'.txt'\n",
    "log_file = open(log_file_name,'w')\n",
    "\n",
    "\n",
    "\n",
    "# call the function: \n",
    "multiple_dir_transfer_with_varied_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
